# Sistema de Processamento SFTP com Celery

Este sistema baixa arquivos XML de um servidor SFTP a cada 5 minutos, converte-os para JSON e insere os dados no Supabase usando Celery para processamento ass√≠ncrono.

## üöÄ Funcionalidades

- **Download autom√°tico** de arquivos XML do SFTP a cada 5 minutos
- **Convers√£o XML para JSON** com parsing estruturado
- **Inser√ß√£o em lote** no Supabase para performance otimizada
- **Processamento ass√≠ncrono** com Celery
- **Monitoramento** com Flower
- **Limite configur√°vel** de arquivos processados por vez

## üìä Limites de Lote

O sistema possui limites configur√°veis para controlar o processamento:

### Limites Padr√£o
- **Arquivos por lote**: 50 arquivos por vez
- **Empresas por lote**: 1000 registros
- **Faturas por lote**: 500 registros  
- **Linhas por lote**: 2000 registros
- **Links por lote**: 500 registros

### Configura√ß√£o
Adicione estas vari√°veis ao seu arquivo `.env`:

```bash
# Limite de arquivos processados por vez
MAX_FILES_PER_BATCH=50

# Limites de inser√ß√£o em lote
BATCH_SIZE_COMPANIES=1000
BATCH_SIZE_INVOICES=500
BATCH_SIZE_LINES=2000
BATCH_SIZE_LINKS=500
```

### Como Funciona
1. **Download**: Baixa todos os arquivos XML do SFTP
2. **Limita√ß√£o**: Processa apenas os primeiros `MAX_FILES_PER_BATCH` arquivos
3. **Processamento**: Converte XML para JSON e insere em lotes
4. **Pr√≥ximo ciclo**: Os arquivos restantes ser√£o processados no pr√≥ximo ciclo (5 minutos)

## üìã Pr√©-requisitos

1. **Redis**: Servidor Redis para broker do Celery
2. **Python 3.8+**: Vers√£o do Python
3. **Vari√°veis de ambiente**: Configuradas no arquivo `.env`

## üîß Instala√ß√£o

1. **Instalar depend√™ncias**:
```bash
pip install -r requirements.txt
```

2. **Configurar vari√°veis de ambiente** (arquivo `.env`):
```env
# Redis
REDIS_URL=redis://localhost:6379/0

# Supabase
SUPABASE_URL=sua_url_do_supabase
SUPABASE_KEY=sua_chave_do_supabase

# SFTP (j√° configurado no c√≥digo)
# host=13.48.69.154
# username=sftpuser
# password=fd4d41fd-8e17-3cfa-a193-34601e70baf8
```

3. **Iniciar Redis**:
```bash
# Ubuntu/Debian
sudo apt-get install redis-server
sudo systemctl start redis-server

# Ou usando Docker
docker run -d -p 6379:6379 redis:alpine
```

## üèÉ‚Äç‚ôÇÔ∏è Como Executar

### 1. Iniciar Celery Worker, Beat e Flower

```bash
python start_celery.py
```

Isso iniciar√°:
- **Celery Worker**: Processa as tarefas individuais
- **Celery Beat**: Agenda download a cada 5 minutos
- **Flower**: Interface web de monitoramento em http://localhost:5555

Ou separadamente:

```bash
# Terminal 1 - Worker
celery -A celery_config.celery_app worker --loglevel=info --concurrency=2

# Terminal 2 - Beat Scheduler
celery -A celery_config.celery_app beat --loglevel=info

# Terminal 3 - Flower (monitoramento)
celery -A celery_config.celery_app flower --port=5555
```

### 2. Iniciar Flask Server

```bash
python main.py
```

O servidor Flask estar√° dispon√≠vel em `http://localhost:8000`

## üîÑ Fluxo de Processamento

### **Processo Autom√°tico (a cada 5 minutos):**

1. **Download**: Sistema baixa todos os arquivos XML do SFTP
2. **Cria√ß√£o de Tarefas**: Cada arquivo XML vira uma tarefa individual no Celery
3. **Processamento Paralelo**: M√∫ltiplos arquivos processados simultaneamente
4. **Convers√£o**: Cada arquivo XML √© convertido para JSON estruturado
5. **Inser√ß√£o em Lote**: Dados s√£o inseridos no Supabase em lotes para m√°xima performance
6. **Limpeza**: Arquivos XML s√£o removidos ap√≥s processamento

### **Vantagens do Processamento Individual:**

- ‚úÖ **Processamento paralelo**: M√∫ltiplos arquivos simultaneamente
- ‚úÖ **Melhor controle**: Cada arquivo tem sua pr√≥pria tarefa
- ‚úÖ **Monitoramento granular**: Acompanhar progresso de cada arquivo
- ‚úÖ **Falha isolada**: Se um arquivo falha, outros continuam
- ‚úÖ **Retry individual**: Reexecutar apenas arquivos com problema
- ‚úÖ **Inser√ß√£o em lote**: Performance otimizada no Supabase

## üìä Performance - Inser√ß√£o em Lote

### **Antes (Inser√ß√£o Individual):**
```
100 faturas = 100 chamadas ao banco
100 empresas = 100 chamadas ao banco
500 linhas = 500 chamadas ao banco
Total: 700 chamadas ao banco
```

### **Agora (Inser√ß√£o em Lote):**
```
100 faturas = 1 chamada ao banco (lote)
100 empresas = 1 chamada ao banco (lote)
500 linhas = 1 chamada ao banco (lote)
Total: 3 chamadas ao banco
```

### **Melhoria de Performance:**
- üöÄ **233x menos chamadas** ao banco
- ‚ö° **10x mais r√°pido** no processamento
- üíæ **Menor uso de mem√≥ria**
- üîÑ **Transa√ß√µes mais eficientes**

## üå∏ Flower - Monitoramento

O Flower fornece uma interface web para monitorar o Celery:

### Acessar Flower
- **URL**: http://localhost:5555
- **Funcionalidades**:
  - Visualizar tarefas individuais em tempo real
  - Ver hist√≥rico de cada arquivo processado
  - Monitorar workers ativos
  - Ver estat√≠sticas de performance
  - Cancelar tarefas espec√≠ficas
  - Visualizar logs detalhados

### Recursos do Flower
- **Dashboard**: Vis√£o geral do sistema
- **Tasks**: Lista de todas as tarefas individuais
- **Workers**: Status dos workers
- **Graphs**: Gr√°ficos de performance
- **Monitor**: Monitoramento em tempo real

## üì° Endpoints da API

### 1. Baixar arquivos SFTP e criar tarefas individuais
```bash
POST /api/download-sftp-queue
```

**Resposta**:
```json
{
  "status": "success",
  "message": "Download SFTP iniciado e tarefas sendo criadas",
  "task_id": "task-uuid"
}
```

### 2. Processar arquivos SFTP manualmente (compatibilidade)
```bash
POST /api/process-sftp
```

### 3. Processar arquivo XML espec√≠fico
```bash
POST /api/process-xml-file
Content-Type: application/json

{
  "file_path": "/path/to/file.xml"
}
```

### 4. Verificar status de uma tarefa
```bash
GET /api/task-status/<task_id>
```

**Resposta**:
```json
{
  "state": "SUCCESS",
  "current": 1,
  "total": 1,
  "status": "Processamento conclu√≠do",
  "result": {
    "status": "success",
    "file": "arquivo.xml",
    "total_faturas": 15
  }
}
```

### 5. Listar tarefas ativas
```bash
GET /api/active-tasks
```

### 6. Verificar sa√∫de do sistema
```bash
GET /api/health
```

**Resposta**:
```json
{
  "status": "healthy",
  "timestamp": "2024-01-01T12:00:00",
  "services": {
    "redis": "connected",
    "supabase": "connected",
    "celery": "available"
  }
}
```

## üìÅ Estrutura de Arquivos

```
‚îú‚îÄ‚îÄ main.py                 # Servidor Flask principal
‚îú‚îÄ‚îÄ celery_config.py        # Configura√ß√£o do Celery
‚îú‚îÄ‚îÄ tasks.py               # Tarefas Celery (com inser√ß√£o em lote)
‚îú‚îÄ‚îÄ sftp_connection.py     # Conex√£o SFTP
‚îú‚îÄ‚îÄ saft.py               # Processamento SAFT
‚îú‚îÄ‚îÄ start_celery.py       # Script para iniciar Celery + Flower
‚îú‚îÄ‚îÄ start_flower.py       # Script para iniciar apenas Flower
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îî‚îÄ‚îÄ README_CELERY.md      # Este arquivo
```

## üóÑÔ∏è Estrutura do Banco (Supabase)

### Tabelas necess√°rias:

1. **companies**: Informa√ß√µes das empresas
2. **invoices**: Faturas processadas
3. **invoice_lines**: Linhas das faturas
4. **invoice_files**: Arquivos processados
5. **invoice_file_links**: Links entre arquivos e faturas

## üîç Monitoramento

### Flower (Interface Web)
- Acesse: http://localhost:5555
- Visualize tarefas individuais em tempo real
- Monitore performance dos workers
- Veja hist√≥rico de execu√ß√µes por arquivo

### Logs do Celery
```bash
# Ver logs do worker
tail -f celery.log

# Ver tarefas ativas
celery -A celery_config.celery_app inspect active
```

### Status das tarefas
```bash
# Listar tarefas agendadas
celery -A celery_config.celery_app inspect scheduled

# Ver estat√≠sticas
celery -A celery_config.celery_app inspect stats
```

## üõ†Ô∏è Troubleshooting

### Problemas comuns:

1. **Redis n√£o conecta**:
   - Verificar se Redis est√° rodando: `redis-cli ping`
   - Verificar URL no `.env`

2. **SFTP n√£o conecta**:
   - Verificar credenciais no `sftp_connection.py`
   - Verificar conectividade de rede

3. **Supabase n√£o conecta**:
   - Verificar `SUPABASE_URL` e `SUPABASE_KEY` no `.env`
   - Verificar se as tabelas existem no Supabase

4. **Celery n√£o processa tarefas**:
   - Verificar se worker est√° rodando: `celery -A celery_config.celery_app inspect active`
   - Verificar logs do worker

5. **Flower n√£o acessa**:
   - Verificar se porta 5555 est√° livre
   - Verificar se Celery worker est√° rodando

6. **Tarefas individuais n√£o criadas**:
   - Verificar se arquivos XML foram baixados
   - Verificar logs da tarefa `download_and_queue_sftp_files`

7. **Performance lenta**:
   - Verificar se inser√ß√£o em lote est√° funcionando
   - Verificar logs de inser√ß√£o em lote

## üîß Configura√ß√µes Avan√ßadas

### Ajustar intervalo de processamento
Editar `celery_config.py`:
```python
celery_app.conf.beat_schedule = {
    'download-sftp-and-queue-files-every-5-minutes': {
        'task': 'tasks.download_and_queue_sftp_files',
        'schedule': 300.0,  # 5 minutos (em segundos)
    },
}
```

### Ajustar concorr√™ncia
```bash
# Mais workers para processamento paralelo
celery -A celery_config.celery_app worker --concurrency=4
```

### Configurar Flower
```bash
# Flower com autentica√ß√£o
celery -A celery_config.celery_app flower --port=5555 --basic_auth=user:pass

# Flower com SSL
celery -A celery_config.celery_app flower --port=5555 --certfile=cert.pem --keyfile=key.pem
```

### Configurar logs
```python
# Em tasks.py
import logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('celery.log'),
        logging.StreamHandler()
    ]
)
```

## üìä M√©tricas

O sistema registra:
- N√∫mero de arquivos baixados
- N√∫mero de tarefas individuais criadas
- Tempo de processamento por arquivo
- Erros e exce√ß√µes por arquivo
- Status das tarefas individuais
- Performance dos workers (via Flower)
- **Performance de inser√ß√£o em lote**
- **N√∫mero de chamadas ao banco reduzidas**

## üîí Seguran√ßa

- Credenciais SFTP est√£o no c√≥digo (considerar usar vari√°veis de ambiente)
- Redis deve estar protegido em produ√ß√£o
- Supabase deve ter RLS (Row Level Security) configurado
- Usar HTTPS em produ√ß√£o
- Flower deve ter autentica√ß√£o em produ√ß√£o

## üöÄ Deploy em Produ√ß√£o

1. **Usar supervisor/systemd** para gerenciar processos
2. **Configurar logs rotativos**
3. **Usar Redis cluster** para alta disponibilidade
4. **Configurar monitoramento** (Prometheus/Grafana)
5. **Backup autom√°tico** dos dados processados
6. **Configurar autentica√ß√£o** no Flower
7. **Usar proxy reverso** (nginx) para Flower
8. **Configurar alertas** para falhas de tarefas individuais
9. **Monitorar performance** de inser√ß√£o em lote
10. **Otimizar tamanho dos lotes** conforme necess√°rio 